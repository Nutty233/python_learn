# PyTorch基础学习相关
本文件于2022/03/18创建于本地，于2022/03/19首次上传至github  
本文件夹用于存储PyTorch基础学习相关数据集及代码  
其中数据集由教程提供，代码部分依照教程手动输入  
并依照自己的理解进行修改及备注，与视频教程稍有不同  

## 文件夹程序及其作用：
### 根据课程引导完成：
    **main.py:**
        判断Torch安装是否成功

    **ReadData.py**
        创建以PIL为核心的图像打开类及数据集的调用和合并
        (也可用CV2，但需注意后续转换为numpy格式时的提前转换)

    **RenameDataset.py**
        用于依照训练集生成相应标注文件(.txt)

    **TestTensorboard.py**
        利用TenserBoard的SummaryWriter函数（快速拥挤功能）
        生成logs文件以完成标量数据统计分析及直观纵览图像输入情况
        (需要在控制台输入指令在网页中打开)

    **TestTransformd.py**
        调用TestTransformd中的函数(工具)用于图像的格式及尺寸变换等操作
        通过输出Tensor图像属性理解tensor类型含有神经网络编程所需参数的作用

    **UsefulTransform.py**
        常见transform介绍（把握输入、输出、作用），推荐常看官方文档（比网上经验准确）
        关注方法需要什么参数，有官方默认值参数的一般不需要自己  定义
        类中特殊的实例方法（__call__()等）介绍
    
    **DatasetTransform.py**
        利用transform批处理Pytorch官网提供的开源数据集
    
    **Dataloader.py**
        利用Dataloader创建数据集加载工具，用于为网络提供数据输入
        实际训练中，一般采用程序中相同的策略：利用for循环将imgs传入神经网络作为输入
    
    **nn_module.py**
        神经网络的基本骨架——nn.Module的使用(利用Torch.nn中的containers进行神经网络骨架搭建) 
        前向传播：input-->forward-->output
        非线性处理：relu；卷积conv

    **nn_conv.py**
        举例介绍Conv2D在图像中的卷积操作：
        weight：权重，卷积核；bias：偏置；
        stride：步长，步径（卷积核滑动量），可以由单个数字（横纵相同）或双数字元组（双向不同）控制步长
        padding：在图像外围进行拓展并填充（默认为0，即不进行填充），一般填充的数字为0

    **nn_conv2d.py**
        神经网络基本结构——卷积层的使用：
        dilation：卷积核卷积单元的对应位距离（空洞卷积）；groups：分组卷积；
        bias：偏置，常年为True；padding_mode：填充模式
        输出通道数 = 输入通道数 * 卷积核的个数？
        看别人的网络时，若没有写明padding或stride时，需要根据PyTorch中Conv2d解释文件下的shape框推导公式进行自行推导
    
    **nn_maxpool.py**
        神经网络基本结构——最大池化的使用：
        目的：保留输入特征并减小数据量；作用：减小数据量，减少计算参数，提升训练速度
        最大池化不改变channel数
        MaxPool：最大池化（下采样）；MaxUnpool：上采样
        池化即运用一个池化核（空滑窗）去提取图像相应数据，并保留一个特征值（最大值、平均值等）
        ceil_mode：默认为false。若为True，当池化核移动到核中存在但不完全是空白时，保留池化结果，为false则跳过

    **nn_relu.py**
        神经网络基本结构——非线性激活：
        为网络中引入非线性特征，以训练出符合各种曲线（特征）的模型，提高泛化能力
        非线性操作之间只存在公式的不同，初始化及引用完全相同
    
    **nn_linear.py**
        神经网络基本结构——线性层及其他层介绍：
        Normalizzation  正则化层（归一化）：将输入正则化 ，加快神经网络训练速度（有文献支持此论点）
                        更容易梯度下降？防止过拟合？
        Dropout         （随机失活层）：在训练过程中，按照指定的概率随机将一些input变成0，可以防止过拟合（有文献支持此论点）
        Linear          线性层（线性连接）；多个输入feature分别乘以相应权重后加相应偏置，生成输出 
                        torch中只需要指定输入输出即可，weight和bais将自动计算
        特定的网络中用的层：        
        Recurrent       特定的网络结构，依照具体需求可以发挥特定作用
        Transform       特定网络结构中的神经网络层
        Sparse          一般用于自然语言处理
        可能重要的层：（自学看一下）
        RNN
        Transform
        embedding
        Torch中也提供了一些训练好的模型可以直接引用

    **nn_seq.py**
        神经网络——简单网络搭建实战和Sequential的使用：
        搭建网络时，若有padding之类的参数不知道具体数值的，需要在官网找推算公式推算得出
        Sequential序列：将网络结构打包，使代码简洁易懂
        以CIFAR10 model为例

    **nn_loss.py**
        损失函数与反向传播
        Loss Function：衡量误差，loss越小越好
            1.计算实际输出和目标之间的差距
            2.未更新输出提供一定的依据（反向传播）:调用损失函数的backward，得到反向传播参数grad（梯度）
              依照梯度利用优化器对参数进行调整，以降低整体误差
        梯度下降：采用反向传播时，将根据梯度将网络中的weight（权重）进行更新调整，以降低损失
            L1Loss：四则运算求差
            Mseloss：平方差
            CrossEntropyLoss：交叉熵，一般应用于（多类别的）分类问题，可从最大似然估计角度理解 
    **nn_loss_network.py**
        神经网络损失函数计算

    **nn_optim.py**
        优化器
        选择合适的优化器，以利用梯度更新神经网络的参数
        优化器操作及描述都在pytorch.optim，其中algorithm部分陈列了一些优化器，优化器的参数因优化器而异
        初学阶段设置params(设定好模型后直接引用)及lr即可，剩下参数默认或参考别人的参数；
            若想理解各优化器的细节要自学下功夫，以下是我找到的讲解连接：
            https://zhuanlan.zhihu.com/p/87209990?from_voters_page=true
        使用优化器的过膝恒也可以看成是一个训练模型的过程，其循环次数成百上千
            训练过程中的误差之和先变小后变大，这是在找误差最小识别率最高的过程，求导可找出极小值作为最优优化模型，具体取最优模型的操作在之后的课程

    **model_pretrained.py**
        现有网络模型的使用及修改
        验证针对现有数据集ImageNet进行训练过的神经网络分类结果（由于数据集过大，放弃）
        改为测试VGG16中pretrained参数为True和False分别有什么差别
        追加及修改（课程里介绍的）或删除（通过替换成空层进行无效化，网上查的）
        
    **model_save.py**
    **model_load.py**
        网络模型的保存与读取（加载）
        方式 1：同时保存（加载）模型的结构和参数。但是对于自己定义的模型还是需要重新定义一遍结构，或直接import模型定义文件
        方式 2（官方推荐）：只保存模型参数，加载时需要先加载初始模型后赋值参数
        综上：由于对于自己定义的模型终究躲不过模型结构重载，所以官方推荐方式二，需要保存的数据量少（仅有参数）
             对于公开模型可常使用方法1，可省去重载模型的步骤

    **model.py**
    **train.py**
    **accuracy.py**
        完整的模型训练套路（以CIFAR10数据集为例）及正确率计算介绍
        从一开始就要养成优秀的写法学习优秀的套路模板（参考官网提供的程序）
        步骤：
            1. 准备数据集
            2. 准备Dataloader
            3. 创建网络模型
            4. 创建损失函数
            5. 创建优化器
            6. 设置训练参数
            7. 设置训练轮数
            8. 调用train()使网络进入训练状态： 
               a. 从训练集中取数据
               b. 计算训练误差
               c. 放到优化器中进行优化
               d. 采用特定方式显示输出（print，writer）
            9. 调用eval()使网络进入测试状态：
               a. 设置with torch.no_grad()剔除梯度
               b. 从测试集中取数据
               c. 计算测试误差
               d. 计算特殊指标
               e. 采用特定方式显示效果（print，writer）
            10. 保存模型
            
    **train_gpu_1.py**
        利用GPU训练模型：
        方法 1：[.cuda()]
            将网络模型，数据（输入，标注），损失函数分别调用.cuda()函数后返回值
            （对于没有GPU的电脑可以使用Google的Colaboratory使用联网免费GPU）
            （新建笔记本，界面和jupyter相似-->修改-->笔记本设置-->GPU，每周30h免费时长）
            （!nvidia-smi查看网络显卡信息）
        方法 2：[.to(device)]（更常用）
            将网络转移到GPU中
            使用CPU：Device = torch.device("CPU")
            指定显卡：torch.device("cuda:0")/不指定显卡：Torch.device("cuda")
            定义device并用.to(device)替代.cuda()


        完整的模型验证套路

        以GitHub代码为例，观摩开源项目，学习优秀代码
        

### 个人练习：
    **VGG16.py**
        尝试重现神经网络VGG16


## 教程及数据集出处：
    B站 PyTorch深度学习快速入门教程（绝对通俗易懂！）【小土堆】
    （B站视频号 74281036）
    感谢该UP主！
